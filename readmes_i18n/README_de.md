<div align="center">

<img src="static/LLMQ.webp" width="400" style="margin-bottom: 10px;">

# ü§ñ LLMQ-Horizon QQ Chatbot

**Intelligenter QQ-Bot basierend auf NoneBot2 und LangGraph, unterst√ºtzt Multimodell-Dialoge, Tool-Aufrufe und Sitzungsmanagement**

<br>

**Tools sind alle mit Function-Calling geschrieben, verwenden keine Plugins, siehe [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling) , [LangChain Tools](https://python.langchain.com/docs/how_to/#tools)**

<br>

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon.svg?type=small)](https://app.fossa.com/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon?ref=badge_small)
[![Docker Release](https://img.shields.io/docker/pulls/bitfennec/llmq-horizon?color=%230077c8&label=Docker%20Pulls&logo=docker&logoColor=white&style=flat)](https://hub.docker.com/r/bitfennec/llmq-horizon)
[![License](https://img.shields.io/github/license/Mgrsc/LLMQ-Horizon?color=%2300c853&label=MIT%20License&style=flat)](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/LICENSE)

<br>

[English](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/readmes_i18n/README_en.md) | [Deutsch](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/readmes_i18n/README_de.md) | [Espa√±ol](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/readmes_i18n/README_es.md) | [Fran√ßais](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/readmes_i18n/README_fr.md) | [Êó•Êú¨Ë™û](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/readmes_i18n/README_ja.md)

</div>

---

## ‚ú® Hauptmerkmale

-   **üîå Umfangreiche Tool-Integration:** Codeausf√ºhrung, Wetterabfrage, Wahrsagerei, Zeichnen usw.
-   **ü§ñ Unterst√ºtzung f√ºr verschiedene gro√üe Modelle:** OpenAI, Google Gemini, Groq usw.
-   **üí¨ Umfangreiches Dialogmanagement:** Gruppenchat/Privatchat, mehrfache Dialoge, Sitzungsisolation
-   **üéØ Flexible Ausl√∂semethoden:** @, Schl√ºsselw√∂rter, Befehlspr√§fix
-   **üé® Multimedia-F√§higkeiten:** Bildanalyse, Audio- und Videoverarbeitung
-   **‚ö° Automatische Sitzungsverwaltung:** Zeit√ºberschreitungsbereinigung, Parallelit√§tskontrolle
-   **ü¶ñ Starke Erweiterbarkeit:** Eigene Tools k√∂nnen geschrieben werden, Tools k√∂nnen nonebot steuern

---

## üöÄ Schnellstart

### 1. Umgebungsvorbereitung f√ºr die Bereitstellung

-   Docker und Docker Compose
-   Stabile Netzwerkumgebung
-   Empfohlenes System: Ubuntu 22.04 und h√∂her, Debian 11 und h√∂her

### 2. Installationsschritte

```bash
# 1. Projekt klonen
git clone https://github.com/Mgrsc/LLMQ-Horizon.git
cd LLMQ-Horizon

# 2. Konfigurationsdateien vorbereiten
cp config-tools.toml.example config-tools.toml
cp config.toml.example config.toml
cd napcat/config/
mv onebot11_qq.json onebot11_<deineQQ>.json  # Durch tats√§chliche QQ-Nummer ersetzen

# 3. Konfiguration √§ndern (siehe Kommentare in den Konfigurationsdateien)
vim config.toml
vim config-tools.toml

# 4. Dienst starten
docker compose up -d

# 5. QR-Code scannen und anmelden
docker compose logs -f

# LLMQ-Dienst neu starten
docker compose restart llmq

# Alle Dienste stoppen
docker compose down
```

## üõ†Ô∏è Tool-Konfiguration

<details>
<summary>üíª Codeausf√ºhrung (Code Runner - Judge0)</summary>

[Judge0 Offizielle Bereitstellungsanleitung](https://github.com/judge0/judge0/blob/master/CHANGELOG.md)

1. **Ubuntu 22.04 oder h√∂here Umgebung und Docker vorbereiten, cgroup v1 konfigurieren:**

    ```bash
    sudo sed -i 's/GRUB_CMDLINE_LINUX=""/GRUB_CMDLINE_LINUX="systemd.unified_cgroup_hierarchy=0"/' /etc/default/grub
    sudo update-grub
    sudo reboot
    ```

2. **Judge0 bereitstellen:**

    ```bash
    wget https://github.com/judge0/judge0/releases/download/v1.13.1/judge0-v1.13.1.zip
    unzip judge0-v1.13.1.zip
    cd judge0-v1.13.1

    # Zwei Passw√∂rter generieren und Passw√∂rter setzen
    openssl rand -hex 32

    # Verwenden Sie die generierten Passw√∂rter, um die Variablen REDIS_PASSWORD und POSTGRES_PASSWORD in der Datei judge0.conf zu aktualisieren.

    # Dienst starten
    docker-compose up -d db redis
    sleep 10s
    docker-compose up -d
    sleep 5s
    ```

    Ihre Judge0 CE v1.13.1-Instanz ist jetzt gestartet und l√§uft; besuchen Sie http://<Ihre Server-IP-Adresse>:2358/docs, um die Dokumentation zu erhalten.

3. **config-tools.toml konfigurieren:**

    ```toml
    [code_generation_running]
    judge0_url = "http://your-server:2358"
    judge0_api_key = "your-api-key"
    ```

</details>

<details>
<summary>üòé Notizen (memos_manage - Memos)</summary>

[Memos Offizielle Bereitstellungsanleitung](https://www.usememos.com/docs/install/container-install)

1. **Ubuntu 22.04 oder h√∂here Umgebung und Docker vorbereiten:**

2. **docker-compose.yaml-Datei erstellen**

    ```yaml
    services:
      memos:
        image: neosmemo/memos:stable
        container_name: memos
        ports:
          - 5230:5230
        volumes:
          - ./memos:/var/opt/memos
        restart: always
    ```

3. **Memos starten**

    ```shell
    docker compose up -d
    ```

    Sie k√∂nnen nun unter http://<Ihre Server-IP-Adresse>:5230 auf Memos zugreifen und die Token in den Einstellungen von Memos abrufen.

4. **Konfigurationsdatei ausf√ºllen**

    ```toml
    [memos]
    url = "http://your-server:xxx"
    memos_token = "<f√ºge die abgerufenen Token ein>"
    default_visibility = "PRIVATE"
    page_size = 10
    user_id = 6
    ```

</details>

## üìù Befehlsbeschreibung

| Befehl                      | Beschreibung                                |
| :------------------------ | :------------------------------------------ |
| `/chat model <Modellname>`   | Dialogmodell wechseln                         |
| `/chat clear`             | Alle Sitzungen l√∂schen                       |
| `/chat group <true/false>` | Gruppenchat-Isolation ein-/ausschalten      |
| `/chat down`              | Dialogfunktion deaktivieren                  |
| `/chat up`                | Dialogfunktion aktivieren                    |
| `/chat chunk <true/false>` | Aktivieren/Deaktivieren von Nachrichten in Teilst√ºcken |


## ü¶ä Tipps zur Prompt-Erstellung

<details>
<summary>1. Grundprinzipien</summary>

-   Klare Anweisungen: Verwenden Sie eine imperative Sprache, um die Bed√ºrfnisse der Benutzer klar zu formulieren und sicherzustellen, dass LLM sie pr√§zise versteht.
-   Referenzbeispiele/Text bereitstellen: Geben Sie detaillierte Beispiele und Informationen, um einen Few-Shot-Prompt zu erstellen, der LLM hilft, das Verst√§ndnis der Absicht zu verbessern.
-   Strukturierter Ausdruck: Verwenden Sie Markierungssymbole (wie XML-Tags, dreifache Anf√ºhrungszeichen, Markdown), um die Lesbarkeit zu verbessern und Prompts klarer auszudr√ºcken.
-   Ausgabesteuerung: Legen Sie Ausgabeformate, Sprachstile und andere Anforderungen fest, um sicherzustellen, dass LLM eine Ausgabe generiert, die den Erwartungen der Benutzer entspricht.
-   Layoutoptimierung: Ordnen Sie das Layout des Prompts sorgf√§ltig an, um das Verst√§ndnis von LLM zu erleichtern.
</details>
<details>
<summary>2. Andere Tipps</summary>

-   Listen Sie die verf√ºgbaren Tools auf und geben Sie Erkl√§rungen und Anforderungen f√ºr komplexe Tools an.
  ```
  create_speech generiert Sprache
    - maximal 40 W√∂rter, keine Emojis erlaubt
    - Unterst√ºtzte Sprachen: Chinesisch, Englisch, Japanisch, Deutsch, Franz√∂sisch, Spanisch, Koreanisch, Arabisch, Russisch, Niederl√§ndisch, Italienisch, Polnisch, Portugiesisch
    - Verf√ºgbare Stimmzuordnungen:
        Klee = keli
        Sigewen = xigewen
        Yae Miko = shenzi
        Ding Zhen = dingzhen
        Lei Jun = leijun
        Lazy Goat = lanyangyang
  ```
-   Fordern Sie die Zusendung der von Tool zur√ºckgegebenen file://-Adresse an.
  ```
    Das Zeichnen, der Abruf von Musik und TTS m√ºssen die zur√ºckgegebenen Links oder Dateipfade an den Benutzer senden.
  ```
-   Beispiel f√ºr die Formatierung des von Tool zur√ºckgegebenen Inhalts
  ```
      # Beispiel f√ºr die Formatierungsoptimierung von Tool-R√ºckgabeinhalten
    Beispiel f√ºr das Format der von get_weather_data zur√ºckgegebenen Daten:
    *   A: Sag mir, wie das Wetter heute in Changsha ist
        T: Ruft das Tool `get_weather_data` ab, um das Wetter abzurufen
        Q:
        üå§Ô∏è {Ort} Wetter
        üåÖ Sonnenaufgang und Sonnenuntergang: {xx:xx}-{xx:xx ohne Jahr}
        ‚è±Ô∏è   Zeit: {Zeit}
        üå°Ô∏è Temperatur: {Temperatur}‚ÑÉ
        üíß Luftfeuchtigkeit: {Luftfeuchtigkeit}%
        üß£ Gef√ºhlte Temperatur: {Gef√ºhlte Temperatur}‚ÑÉ
        üçÉ Windrichtung und Windgeschwindigkeit: {Windrichtung}-{Windgeschwindigkeit}
        üìã Gesamtstatus: {Gesamtanalyse}
        Baby, zieh dich warm an, wenn du ausgehst~ sei vorsichtig vor einer Erk√§ltung
  ```
</details>

## ‚ùó H√§ufige Fragen

Alle Tools wurden getestet. Wenn es Probleme gibt, beziehen Sie sich bitte auf die folgenden √úberpr√ºfungen.

<details>
<summary>1. Anmeldefehler</summary>

-   √úberpr√ºfen Sie, ob die QQ-Nummernkonfiguration korrekt ist.
-   Best√§tigen Sie das Format der napcat-Konfigurationsdatei.
-   √úberpr√ºfen Sie die napcat-Containerprotokolle, um das Problem zu beheben.

</details>

<details>
<summary>2. Tool-Aufruf fehlgeschlagen</summary>

-   Best√§tigen Sie, dass das Modell die Funktion zum Aufrufen von Funktionen unterst√ºtzt.
-   √úberpr√ºfen Sie die zugeh√∂rigen API-Schl√ºsselkonfigurationen.
-   √úberpr√ºfen Sie die LLMQ-Containerprotokolle, um den Fehler zu lokalisieren.
-   F√ºgen Sie [LangSmith](https://smith.langchain.com/) im Docker-Container hinzu, um zu debuggen.

    ```yaml
    environment:
      - LANGCHAIN_TRACING_V2=true
      - LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
      - LANGCHAIN_API_KEY="<dein_api_schl√ºssel>"
      - LANGCHAIN_PROJECT="<dein_projektname>"
    ```

</details>

<details>
<summary>3. Andere Probleme</summary>

-   Bei anderen Problemen treten Sie bitte der QQ-Gruppe zur Diskussion bei.
    ![qrcode](static/qrcode.jpg)

</details>

## üîó Zugeh√∂rige Projekte

-   [NoneBot2](https://github.com/nonebot/nonebot2)
-   [LangGraph](https://github.com/langchain-ai/langgraph)
-   [LangChain](https://github.com/langchain-ai/langchain)
-   [Judge0](https://github.com/judge0/judge0)
-   [Memos](https://github.com/usememos/memos)
-   [NapCat](https://github.com/NapNeko/NapCatQQ)

## üìÑ Lizenz

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon.svg?type=large&issueType=license)](https://app.fossa.com/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon?ref=badge_large&issueType=license)

Dieses Projekt ist unter der [MIT-Lizenz](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/LICENSE) lizenziert.

Copyright ¬© 2024 Bitfennec.

---