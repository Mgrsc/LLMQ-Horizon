<div align="center">

<img src="static/LLMQ.webp" width="400" style="margin-bottom: 10px;">

# ü§ñ LLMQ-Horizon Robot de Chat QQ

**Un robot QQ intelligent bas√© sur NoneBot2 et LangGraph, prenant en charge les conversations multimod√®les, l'appel d'outils et la gestion de sessions**

<br>

**Les outils sont tous √©crits en utilisant Function-calling, sans utiliser de plugins, voir [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling) , [LangChain Tools](https://python.langchain.com/docs/how_to/#tools)**

<br>

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon.svg?type=small)](https://app.fossa.com/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon?ref=badge_small)
[![Docker Release](https://img.shields.io/docker/pulls/bitfennec/llmq-horizon?color=%230077c8&label=Docker%20Pulls&logo=docker&logoColor=white&style=flat)](https://hub.docker.com/r/bitfennec/llmq-horizon)
[![License](https://img.shields.io/github/license/Mgrsc/LLMQ-Horizon?color=%2300c853&label=Licence%20MIT&style=flat)](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/LICENSE)

</div>

---

## ‚ú® Principales Caract√©ristiques

-   **üîå Int√©gration d'outils riches :** Ex√©cution de code, pr√©visions m√©t√©orologiques, divination, dessin, etc.
-   **ü§ñ Prise en charge de divers grands mod√®les :** OpenAI, Google Gemini, Groq, etc.
-   **üí¨ Gestion compl√®te des dialogues :** Chat de groupe/priv√©, conversations √† plusieurs tours, isolation des sessions
-   **üéØ Modes de d√©clenchement flexibles :** @, mots-cl√©s, pr√©fixes de commande
-   **üé® Capacit√©s multim√©dias :** Analyse d'images, traitement audio et vid√©o
-   **‚ö° Gestion automatique des sessions :** Nettoyage des d√©lais d'attente, contr√¥le de la concurrence
-   **ü¶ñ Forte capacit√© d'extension :** Possibilit√© d'√©crire des outils soi-m√™me, possibilit√© d'utiliser des outils pour contr√¥ler nonebot

---

## üöÄ D√©marrage Rapide

### 1. Pr√©paration de l'environnement de d√©ploiement

-   Docker et Docker Compose
-   Environnement r√©seau stable
-   Syst√®mes recommand√©s : Ubuntu 22.04 et versions ult√©rieures, Debian 11 et versions ult√©rieures

### 2. √âtapes d'installation

```bash
# 1. Cloner le projet
git clone https://github.com/Mgrsc/LLMQ-Horizon.git
cd LLMQ-Horizon

# 2. Pr√©parer les fichiers de configuration
cp config-tools.toml.example config-tools.toml
cp config.toml.example config.toml
cd napcat/config/
mv onebot11_qq.json onebot11_<votreQQ>.json  # Remplacer par votre num√©ro QQ r√©el

# 3. Modifier la configuration (se r√©f√©rer aux commentaires dans les fichiers de configuration pour la modification)
vim config.toml
vim config-tools.toml

# 4. D√©marrer le service
docker compose up -d

# 5. Scanner pour se connecter
docker compose logs -f

# Red√©marrer le service LLMQ
docker compose restart llmq

# Arr√™ter tous les services
docker compose down
```

## üõ†Ô∏è Configuration des Outils

<details>
<summary>üíª Ex√©cution de Code (Code Runner - Judge0)</summary>

[Tutoriel de d√©ploiement officiel de Judge0](https://github.com/judge0/judge0/blob/master/CHANGELOG.md)

1. **Pr√©parer un environnement Ubuntu 22.04 ou sup√©rieur et Docker, configurer cgroup v1 :**

    ```bash
    sudo sed -i 's/GRUB_CMDLINE_LINUX=""/GRUB_CMDLINE_LINUX="systemd.unified_cgroup_hierarchy=0"/' /etc/default/grub
    sudo update-grub
    sudo reboot
    ```

2. **D√©ployer Judge0 :**

    ```bash
    wget https://github.com/judge0/judge0/releases/download/v1.13.1/judge0-v1.13.1.zip
    unzip judge0-v1.13.1.zip
    cd judge0-v1.13.1

    # G√©n√©rer deux mots de passe et d√©finir les mots de passe
    openssl rand -hex 32

    # Utiliser les mots de passe g√©n√©r√©s pour mettre √† jour les variables REDIS_PASSWORD et POSTGRES_PASSWORD dans le fichier judge0.conf.

    # D√©marrer le service
    docker-compose up -d db redis
    sleep 10s
    docker-compose up -d
    sleep 5s
    ```

    Votre instance Judge0 CE v1.13.1 est maintenant d√©marr√©e et en fonctionnement¬†; consultez http://<Votre adresse IP de serveur>:2358/docs pour obtenir la documentation.

3. **Configurer config-tools.toml¬†:**

    ```toml
    [code_generation_running]
    judge0_url = "http://votre-serveur:2358"
    judge0_api_key = "votre-cl√©-api"
    ```

</details>

<details>
<summary>üòé M√©mos (memos_manage - Memos)</summary>

[Tutoriel de d√©ploiement officiel de Memos](https://www.usememos.com/docs/install/container-install)

1. **Pr√©parer un environnement Ubuntu 22.04 ou sup√©rieur et Docker¬†:**

2. **R√©diger le fichier docker-compose.yaml**

    ```yaml
    services:
      memos:
        image: neosmemo/memos:stable
        container_name: memos
        ports:
          - 5230:5230
        volumes:
          - ./memos:/var/opt/memos
        restart: always
    ```

3. **D√©marrer memos**

    ```shell
    docker compose up -d
    ```

    Vous pouvez maintenant acc√©der √† memos sur http://<Votre adresse IP de serveur>:5230, et obtenir des jetons dans les Param√®tres de memos.

4. **Remplir le fichier de configuration**

    ```toml
    [memos]
    url = "http://votre-serveur:xxx"
    memos_token = "<Entrez les jetons obtenus>"
    default_visibility = "PRIVATE"
    page_size = 10
    user_id = 6
    ```

</details>

## üìù Description des Commandes

| Commande                       | Description                               |
| :----------------------------- | :---------------------------------------- |
| `/chat model <nom du mod√®le>` | Changer le mod√®le de conversation          |
| `/chat clear`                  | Effacer toutes les conversations         |
| `/chat group <true/false>`     | Activer/d√©sactiver l'isolation des groupes |
| `/chat down`                   | D√©sactiver la fonctionnalit√© de conversation |
| `/chat up`                     | Activer la fonctionnalit√© de conversation  |
| `/chat chunk <true/false>`      | Activer/d√©sactiver l'envoi par segments    |

## ‚ùó Probl√®mes courants

<details>
<summary>1. √âchec de la connexion</summary>

-   V√©rifier si la configuration du num√©ro QQ est correcte
-   Confirmer le format du fichier de configuration napcat
-   Consulter les journaux du conteneur napcat pour identifier les probl√®mes

</details>

<details>
<summary>2. √âchec de l'appel d'outils</summary>

-   Confirmer que le mod√®le prend en charge la capacit√© d'appel de fonctions
-   V√©rifier la configuration des cl√©s API associ√©es
-   Consulter les journaux du conteneur LLMQ pour localiser l'erreur
-   Dans le conteneur Docker, ajouter [LangSmith](https://smith.langchain.com/) pour le d√©bogage

    ```yaml
    environment:
      - LANGCHAIN_TRACING_V2=true
      - LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
      - LANGCHAIN_API_KEY="<votre_cl√©_api>"
      - LANGCHAIN_PROJECT="<votre_nom_de_projet>"
    ```

</details>

<details>
<summary>3. Autres probl√®mes</summary>

-   Pour d'autres probl√®mes, veuillez rejoindre le groupe QQ pour en discuter
    ![qrcode](static/qrcode.jpg)

</details>

## üîó Projets Associ√©s

-   [NoneBot2](https://github.com/nonebot/nonebot2)
-   [LangGraph](https://github.com/langchain-ai/langgraph)
-   [LangChain](https://github.com/langchain-ai/langchain)
-   [Judge0](https://github.com/judge0/judge0)
-   [Memos](https://github.com/usememos/memos)
-   [NapCat](https://github.com/NapNeko/NapCatQQ)

## üìÑ Licence

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon.svg?type=large&issueType=license)](https://app.fossa.com/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon?ref=badge_large&issueType=license)

Ce projet est sous [licence MIT](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/LICENSE).

Copyright ¬© 2024 Bitfennec.

---