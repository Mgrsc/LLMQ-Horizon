<div align="center">

<img src="static/LLMQ.webp" width="400" style="margin-bottom: 10px;">

# ü§ñ LLMQ-Horizon Bot de Chat QQ

**Un bot inteligente de QQ basado en NoneBot2 y LangGraph, que admite conversaciones con m√∫ltiples modelos, llamadas a herramientas y gesti√≥n de sesiones**

<br>

**Las herramientas est√°n escritas usando Function-calling, sin usar plugins, con referencia a [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling) y [LangChain Tools](https://python.langchain.com/docs/how_to/#tools)**

<br>

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon.svg?type=small)](https://app.fossa.com/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon?ref=badge_small)
[![Docker Release](https://img.shields.io/docker/pulls/bitfennec/llmq-horizon?color=%230077c8&label=Docker%20Pulls&logo=docker&logoColor=white&style=flat)](https://hub.docker.com/r/bitfennec/llmq-horizon)
[![License](https://img.shields.io/github/license/Mgrsc/LLMQ-Horizon?color=%2300c853&label=MIT%20License&style=flat)](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/LICENSE)

<br>

[Ingl√©s](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/readmes_i18n/README_en.md) | [Alem√°n](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/readmes_i18n/README_de.md) | [Espa√±ol](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/readmes_i18n/README_es.md) | [Franc√©s](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/readmes_i18n/README_fr.md) | [Japon√©s](https://github.com/Mgrsc/LLMQ-Horizon/blob/main/readmes_i18n/README_ja.md)

</div>

---

## ‚ú® Caracter√≠sticas Principales

-   **üîå Amplia integraci√≥n de herramientas:** Ejecuci√≥n de c√≥digo, consulta del clima, adivinaci√≥n, dibujo, etc.
-   **ü§ñ Soporte para m√∫ltiples modelos grandes:** OpenAI, Google Gemini, Groq, etc.
-   **üí¨ Gesti√≥n completa de conversaciones:** Chats grupales/privados, conversaciones de varios turnos, aislamiento de sesiones
-   **üéØ M√©todos de activaci√≥n flexibles:** @, palabras clave, prefijos de comandos
-   **üé® Capacidades multimedia:** An√°lisis de im√°genes, procesamiento de audio y video
-   **‚ö° Gesti√≥n autom√°tica de sesiones:** Limpieza por tiempo de espera, control de concurrencia
-   **ü¶ñ Potente capacidad de expansi√≥n:** Posibilidad de escribir herramientas propias y de usar herramientas para controlar nonebot

---

## üöÄ Inicio R√°pido

### 1. Preparaci√≥n del entorno de implementaci√≥n

-   Docker y Docker Compose
-   Entorno de red estable
-   Sistema recomendado: Ubuntu 22.04 y superior, Debian 11 y superior

> Nota: Al activar herramientas con el modelo deepseek, no use m√°s de 5, y las indicaciones deben ser lo m√°s breves posible. De lo contrario, deepseek llamar√° a las herramientas sin parar y las saturar√°, o simplemente no las usar√°.

### 2. Pasos de instalaci√≥n

```bash
# 1. Clona el proyecto
git clone https://github.com/Mgrsc/LLMQ-Horizon.git
cd LLMQ-Horizon

# 2. Prepara los archivos de configuraci√≥n
cp config-tools.toml.example config-tools.toml
cp config.toml.example config.toml
cd napcat/config/
mv onebot11_qq.json onebot11_<tu_QQ>.json  # Reemplaza con tu n√∫mero de QQ real

# 3. Modifica la configuraci√≥n (consulta los comentarios en los archivos de configuraci√≥n)
vim config.toml
vim config-tools.toml

# 4. Inicia el servicio
docker compose up -d

# 5. Escanea el c√≥digo QR para iniciar sesi√≥n
docker compose logs -f

# Reinicia el servicio LLMQ
docker compose restart llmq

# Det√©n todos los servicios
docker compose down
```

## üõ†Ô∏è Configuraci√≥n de Herramientas

<details>
<summary>üíª Ejecuci√≥n de C√≥digo (Code Runner - Judge0)</summary>

[Tutorial oficial de despliegue de Judge0](https://github.com/judge0/judge0/blob/master/CHANGELOG.md)

1. **Prepara un entorno Ubuntu 22.04 o superior y Docker, configura cgroup v1:**

    ```bash
    sudo sed -i 's/GRUB_CMDLINE_LINUX=""/GRUB_CMDLINE_LINUX="systemd.unified_cgroup_hierarchy=0"/' /etc/default/grub
    sudo update-grub
    sudo reboot
    ```

2. **Despliega Judge0:**

    ```bash
    wget https://github.com/judge0/judge0/releases/download/v1.13.1/judge0-v1.13.1.zip
    unzip judge0-v1.13.1.zip
    cd judge0-v1.13.1

    # Genera dos contrase√±as y config√∫ralas
    openssl rand -hex 32

    # Usa las contrase√±as generadas para actualizar las variables REDIS_PASSWORD y POSTGRES_PASSWORD en el archivo judge0.conf.

    # Inicia el servicio
    docker-compose up -d db redis
    sleep 10s
    docker-compose up -d
    sleep 5s
    ```

    Tu instancia Judge0 CE v1.13.1 ahora est√° iniciada y funcionando; accede a http://<la direcci√≥n IP de tu servidor>:2358/docs para obtener la documentaci√≥n.

3. **Configura config-tools.toml:**

    ```toml
    [code_generation_running]
    judge0_url = "http://tu-servidor:2358"
    judge0_api_key = "tu-api-key"
    ```

</details>

<details>
<summary>üìù Notas (memos_manage - Memos)</summary>

[Tutorial oficial de despliegue de Memos](https://www.usememos.com/docs/install/container-install)

1. **Prepara el entorno:**
   - Ubuntu 22.04 y superior
   - Docker y Docker Compose

2. **Escribe el archivo docker-compose.yaml**

    ```yaml
    services:
      memos:
        image: neosmemo/memos:stable
        container_name: memos
        ports:
          - 5230:5230
        volumes:
          - ./memos:/var/opt/memos
        restart: always
    ```

3. **Inicia el servicio:**
```bash
docker compose up -d
```

Ahora puedes acceder a memos en http://<la direcci√≥n IP de tu servidor>:5230, y obtener los Tokens en la configuraci√≥n de memos.

4. **Configura config-tools.toml:**

```toml
[memos_manage]
url = "http://tu-servidor:5230"
memos_token = "tu-memos-token"  # Token obtenido desde la p√°gina de configuraci√≥n
default_visibility = "PRIVATE"
page_size = 10
user_id = 6
```
</details>

<details>
<summary>üì∞ Obtenci√≥n de noticias (get_news - SynapseNews)</summary>

[Direcci√≥n del proyecto SynapseNews](https://github.com/Mgrsc/SynapseNews)

1. **Pasos de despliegue:**
```bash
git clone https://github.com/Mgrsc/SynapseNews.git
cd synapsenews
# Configura config.toml
docker compose up -d
```
</details>

## üìù Descripci√≥n de Comandos

| Comando                      | Descripci√≥n                             |
| :------------------------ | :-------------------------------------- |
| `/chat model <nombre_modelo>`   | Cambiar el modelo de conversaci√≥n       |
| `/chat clear`             | Limpiar todas las sesiones               |
| `/chat group <true/false>` | Activar/desactivar el aislamiento de grupos |
| `/chat down`              | Desactivar la funci√≥n de conversaci√≥n  |
| `/chat up`                | Activar la funci√≥n de conversaci√≥n     |
| `/chat chunk <true/false>` | Activar/desactivar el env√≠o por fragmentos |

## ü¶ä Consejos para la Elaboraci√≥n de Indicaciones

<details>
<summary>1. Principios B√°sicos</summary>

-   Instrucciones claras: Utilizar lenguaje imperativo para establecer las necesidades del usuario, asegurando que el LLM pueda entender con precisi√≥n.
-   Proporcionar ejemplos/texto de referencia: Ofrecer ejemplos e informaci√≥n detallada, configurando un Prompt de pocos disparos para ayudar al LLM a mejorar la comprensi√≥n de la intenci√≥n.
-   Expresi√≥n estructurada: Usar s√≠mbolos de marcado (como etiquetas XML, comillas triples, Markdown) para mejorar la legibilidad, haciendo que las indicaciones sean claras.
-   Control de salida: Especificar los requisitos de formato de salida, estilo de lenguaje, etc., para garantizar que el LLM genere una salida que cumpla con las expectativas del usuario.
-   Optimizaci√≥n del dise√±o: Organizar cuidadosamente el dise√±o del Prompt para facilitar la comprensi√≥n del LLM.
</details>

<details>
<summary>2. Otros Consejos</summary>

-   Enumerar las herramientas disponibles, explicando y requiriendo las herramientas complejas.
  ```
  create_speech generar voz
    - M√°ximo 40 caracteres, sin emojis
    - Idiomas admitidos: chino, ingl√©s, japon√©s, alem√°n, franc√©s, espa√±ol, coreano, √°rabe, ruso, holand√©s, italiano, polaco, portugu√©s
    - Asignaciones de voces disponibles:
        ÂèØËéâ = keli
        Ë•øÊ†ºÈõØ = xigewen
        Á•ûÂ≠ê = shenzi
        ‰∏ÅÁúü = dingzhen
        Èõ∑ÂÜõ = leijun
        ÊáíÁæäÁæä = lanyangyang
  ```
-   Solicitar el env√≠o de la direcci√≥n file:// devuelta por la herramienta.
  ```
    El dibujo, la obtenci√≥n de m√∫sica y la funci√≥n TTS deben enviar la direcci√≥n del enlace o la ruta del archivo al usuario
  ```
-   Ejemplo de formato de la salida de la herramienta.
  ```
      # Ejemplo de optimizaci√≥n del formato de salida de la herramienta
    Ejemplo de formato de datos devueltos por get_weather_data:
    *   A: Dime el clima de Changsha hoy
        T: Llamar a la herramienta `get_weather_data` para obtener el clima
        Q:
        üå§Ô∏è Clima en {lugar}
        üåÖ Salida y puesta del sol: {xx:xx}-{xx:xx sin a√±o}
        ‚è±Ô∏è   Hora: {hora}
        üå°Ô∏è Temperatura: {temperatura}‚ÑÉ
        üíß Humedad: {humedad}%
        üß£ Sensaci√≥n t√©rmica: {sensaci√≥n t√©rmica}‚ÑÉ
        üçÉ Direcci√≥n y velocidad del viento: {direcci√≥n del viento}-{velocidad del viento}
        üìã Estado general: {an√°lisis general}
        ¬°Cari√±o, abr√≠gate al salir para no resfriarte!
  ```
</details>

## ü§ù Gu√≠a de Contribuci√≥n

1. Haz un fork de este repositorio
2. Crea tu rama de funci√≥n (`git checkout -b feature/AmazingFeature`)
3. Env√≠a tus cambios (`git commit -m 'A√±ade una caracter√≠stica incre√≠ble'`)
4. Sube a la rama (`git push origin feature/AmazingFeature`)
5. Abre una solicitud de extracci√≥n (Pull Request)

## ü§ñ Preguntas Frecuentes
Todas las herramientas han sido probadas. Si hay alg√∫n problema, consulta la siguiente verificaci√≥n.

<details>
<summary>1. Fallo al iniciar sesi√≥n</summary>

-   Comprueba si la configuraci√≥n del n√∫mero de QQ es correcta.
-   Confirma el formato del archivo de configuraci√≥n de napcat.
-   Consulta los registros del contenedor napcat para solucionar el problema.

</details>

<details>
<summary>2. Fallo al llamar a la herramienta</summary>

-   Confirma que el modelo admite la capacidad de llamada a funciones.
-   Comprueba la configuraci√≥n de las claves de la API relacionadas.
-   Consulta los registros del contenedor LLMQ para localizar el error.
-   A√±ade [LangSmith](https://smith.langchain.com/) al contenedor docker para depurar.

    ```yaml
    environment:
      - LANGCHAIN_TRACING_V2=true
      - LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
      - LANGCHAIN_API_KEY="<tu_api_key>"
      - LANGCHAIN_PROJECT="<nombre_de_tu_proyecto>"
    ```

</details>

<details>
<summary>3. Otros problemas</summary>

-   Para otros problemas, √∫nete al grupo de QQ para discutir.
    ![qrcode](static/qrcode.jpg)

</details>

## üîó Proyectos Relacionados

-   [NoneBot2](https://github.com/nonebot/nonebot2)
-   [LangGraph](https://github.com/langchain-ai/langgraph)
-   [LangChain](https://github.com/langchain-ai/langchain)
-   [Judge0](https://github.com/judge0/judge0)
-   [Memos](https://github.com/usememos/memos)
-   [NapCat](https://github.com/NapNeko/NapCatQQ)

## üìÑ Licencia

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon.svg?type=large&issueType=license)](https://app.fossa.com/projects/git%2Bgithub.com%2FMgrsc%2FLLMQ-Horizon?ref=badge_large&issueType=license)
Este proyecto tiene licencia MIT - consulta el archivo [LICENSE](LICENSE) para obtener detalles.
Copyright ¬© 2024 Bitfennec.
---