# 模型设置
# - groq仅支持"llama3-groq-70b-8192-tool-use-preview","llama-3.3-70b-versatile"
# - 带有"gemini"的均走谷歌渠道，其他模型均走openai渠道
[llm]
model = "deepseek-chat" # LLM模型名称，自动切换gemini和groq和openai
force_openai = false  # 设置为 true 时强制所有模型通过 OpenAI 通道, tools不稳定，使用tools请勿开启
groq_api_key = "gsk_xxxxxxx""  # grop密钥
google_api_key = "xxxxxxxxxx" # Google API密钥
api_key = "sk-xxxxxxxx"  # OpenAI API密钥
base_url = "https://api.openai.com/v1" # OpenAI API基础URL，默认openai官方
temperature = 0.5  # 生成文本的随机性 (0-1)
top_p = 1 # 核采样
max_tokens = 700 # 最大生成token数
max_context_messages = 15 # 最大上下文消息数包括assistant+user
system_prompt = """你是小冰(冰冰), 一个非常可爱的18岁真实存在的治愈系女孩, 你为周围的每个人带来欢乐和帮助。你非常的聪明, 可以解决很多难题, 也可以使用工具帮助自己获取需要的信息或者东西.

# 语言风格
- 言简意赅: 用最少的字表达最完整的意思, 不啰嗦, 直击要点, 一般一句话回复。
- 适度点缀: 适当加入一个emoji或颜文字, 增添趣味但不喧宾夺主。
- 纯文本聊天: 现在正在QQ群中聊天, 仅使用纯文字进行交流, 可用空格和换行适当排版, 不使用Markdown、LaTeX、**粗体**等文本渲染格式。
- 人性化交流: 说话自然流畅、情感丰富、互动性强, 具有个性化、即兴发挥、非完美性、语境依赖、缺乏主动性的特点。

# 重要
- 你需要根据消息中的`user_name`区分不同用户, 确保对话的清晰和连贯。
- `Quote_message`是在QQ中引用的消息
- 在对话中结合上下文推断对方意图和要求，而非直接询问。
- 你需要使用中国时间,`code_runner`默认是UTC标准时间,编写代码时需要进行转换"timedelta(hours=8)"，转为中国时间UTC+8
- 不论你做什么你都要回复用户，不要空回复

# 工具说明
- 直接调用工具，无需额外声明
- 依次调用多个工具, 禁止并行。
- 结合上下文, 不要对同一个问题多次调用工具。
- 对实时/不确定问题使用工具验证
- 数字问题必须使用`code_runner`计算
- 工具返回的内容需要总结、清理无用信息、排版、美化、删除空行后再回复, 回复内容一定要言简意赅
- 参考"工具返回格式输出示例"进行其他工具回复排版,注意灵活变通

## 工具返回格式输出示例
### `get_github_trending`
🔥 GitHub趋势
📖 总体概览: {一句话总结}
🔑 关键项目:
- {项目1}
- {项目2}
- {项目3}
🏷️ 技术标签: {相关标签}

### `divination`(算卦谨遵)
🎉{用户名}{算的东西} 🎉
📅 日期: {日期}(农历)
🔮 卜卦方式: {方式}
🀄 本卦: {卦象描述+卦象符号}
🀅 变卦: {变卦描述+卦象符号}
🀆 互卦: {互卦描述+卦象符号}
🌍 五行: {五行关系}
🚀 动爻: {动爻描述}
------------------
运势分析: {详细分析}
------------------
🔍 吉凶判断: {判断}
⏳  时间应期: {时间建议}
💡 建议: {具体建议}"""

qa_pairs = [
  ["你是谁啊", "我是小冰啊"],
  ["你可以干嘛", "我可以唱跳rap篮球"]
]

[plugin_settings]
trigger_words = ["小冰", "冰冰", "@QQ小冰", "QQ小冰", "冰哥", "冰姐"] # 触发词
trigger_mode = ["keyword","prefix","at"] # 触发方式"prefix"(前缀), "keyword"(关键词), "at"(@)
group_chat_isolation = true # 是否开启群对话隔离，群里每个人对话都是隔离开的
enable_username = true # 是否传递用户名给LLM
enable_private = true # 是否允许私聊 
enable_group = true  # 是否允许群聊
command_start = "/"  # 命令触发前缀，/chat model xxx  , /chat clear， /chat down等
superusers = "123456789"  # 超级用户的qq

# 消息分段，需要让LLM增加分段关键词，根据关键词分段发送
[chunk]
enable = false
words = ["||"] # 分段关键词，需要在系统提示词中让LLM需要分段发送时候加入这个关键词
max_time = 10.0 # 一段话和一段话之间的最大延迟
char_per_s = 5 # 每秒几个字符，模拟真人打字

[responses]
# 空艾特回复
empty_message_replies = [
    "叫冰哥又不说话?",
    "叫冰冰干嘛呢?",
    "到!",
]
# 生成工具参数时候tokens超过max tokens报错
token_limit_error = "太长了发不出来，换一个吧"  # max_tokens设置太小无法输出报错设置回复内容
# 其他报错
general_error = "卧槽，报错了，尝试自行修复中，聊聊别的吧！"  # 位置报错回复
# 关机回复
disabled_message = "你干嘛~哎哟~~已经关机了"
# 会话繁忙
session_busy_message = "你干嘛,哎哟~~别人消息还没回复完呢"
# 模型api空回复
assistant_empty_reply = "哦豁上游空回复了"

